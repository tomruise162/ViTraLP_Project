{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Env checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1\n",
      "True\n",
      "NVIDIA GeForce RTX 4050 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)                   # In ra version, ví dụ 2.5.1\n",
    "print(torch.cuda.is_available())           # True nếu GPU dùng được\n",
    "print(torch.cuda.get_device_name(0))       # Tên GPU nếu có\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.10.0\n",
      "Num GPUs Available: 1\n",
      "GPU Name: /physical_device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(\"Num GPUs Available:\", len(gpus))\n",
    "for gpu in gpus:\n",
    "    print(\"GPU Name:\", gpu.name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YOLO Detecting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\Users\\ADMIN\\Desktop\\test_real\\results\\heavy\\Dieu_0269_png.rf.ae3a7d4751b1ab6bd2efded1dd2fcf32.jpg: 640x640 1 LP, 6.5ms\n",
      "Speed: 2.0ms preprocess, 6.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\ADMIN\\Desktop\\test_real\\results\\heavy\\Dieu_0269_png.rf.bb70c387d8e9f8c951a2447f63c4c894.jpg: 640x640 1 LP, 5.8ms\n",
      "Speed: 2.0ms preprocess, 5.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\ADMIN\\Desktop\\test_real\\results\\heavy\\Dieu_0269_png.rf.e9f24a1e2e608c2cb3471d5a47be62ab.jpg: 640x640 1 LP, 7.1ms\n",
      "Speed: 2.7ms preprocess, 7.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\ADMIN\\Desktop\\test_real\\results\\heavy\\Dieu_0277_png.rf.1e63158cf701baedf83e2f4bda73318b.jpg: 640x640 1 LP, 5.1ms\n",
      "Speed: 1.8ms preprocess, 5.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\ADMIN\\Desktop\\test_real\\results\\heavy\\Dieu_0277_png.rf.2d7438662ce4848d6f19bce0eb158043.jpg: 640x640 1 LP, 5.0ms\n",
      "Speed: 1.8ms preprocess, 5.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\ADMIN\\Desktop\\test_real\\results\\heavy\\Dieu_0277_png.rf.e1eceac15c516d34668a829641b62911.jpg: 640x640 1 LP, 6.4ms\n",
      "Speed: 1.8ms preprocess, 6.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\ADMIN\\Desktop\\test_real\\results\\heavy\\Dieu_0297_png.rf.2e02ec770094214aebe84fb37f4af7b8.jpg: 640x640 1 LP, 5.4ms\n",
      "Speed: 1.9ms preprocess, 5.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\ADMIN\\Desktop\\test_real\\results\\heavy\\Dieu_0297_png.rf.cba8d93ea7a38d0fc0cbe3a5046dd4a4.jpg: 640x640 1 LP, 5.7ms\n",
      "Speed: 1.9ms preprocess, 5.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\ADMIN\\Desktop\\test_real\\results\\heavy\\Dieu_0297_png.rf.d3702cc1d5eac01c05cb3e46b194cb47.jpg: 640x640 1 LP, 6.4ms\n",
      "Speed: 1.9ms preprocess, 6.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Cropped plates for C:\\Users\\ADMIN\\Desktop\\test_real\\results\\heavy\\Dieu_0269_png.rf.ae3a7d4751b1ab6bd2efded1dd2fcf32.jpg:\n",
      " - D:\\ViTraLP\\output_yolo_crop_test\\Dieu_0269_png.rf.ae3a7d4751b1ab6bd2efded1dd2fcf32_plate_0.jpg\n",
      "Cropped plates for C:\\Users\\ADMIN\\Desktop\\test_real\\results\\heavy\\Dieu_0269_png.rf.bb70c387d8e9f8c951a2447f63c4c894.jpg:\n",
      " - D:\\ViTraLP\\output_yolo_crop_test\\Dieu_0269_png.rf.bb70c387d8e9f8c951a2447f63c4c894_plate_0.jpg\n",
      "Cropped plates for C:\\Users\\ADMIN\\Desktop\\test_real\\results\\heavy\\Dieu_0269_png.rf.e9f24a1e2e608c2cb3471d5a47be62ab.jpg:\n",
      " - D:\\ViTraLP\\output_yolo_crop_test\\Dieu_0269_png.rf.e9f24a1e2e608c2cb3471d5a47be62ab_plate_0.jpg\n",
      "Cropped plates for C:\\Users\\ADMIN\\Desktop\\test_real\\results\\heavy\\Dieu_0277_png.rf.1e63158cf701baedf83e2f4bda73318b.jpg:\n",
      " - D:\\ViTraLP\\output_yolo_crop_test\\Dieu_0277_png.rf.1e63158cf701baedf83e2f4bda73318b_plate_0.jpg\n",
      "Cropped plates for C:\\Users\\ADMIN\\Desktop\\test_real\\results\\heavy\\Dieu_0277_png.rf.2d7438662ce4848d6f19bce0eb158043.jpg:\n",
      " - D:\\ViTraLP\\output_yolo_crop_test\\Dieu_0277_png.rf.2d7438662ce4848d6f19bce0eb158043_plate_0.jpg\n",
      "Cropped plates for C:\\Users\\ADMIN\\Desktop\\test_real\\results\\heavy\\Dieu_0277_png.rf.e1eceac15c516d34668a829641b62911.jpg:\n",
      " - D:\\ViTraLP\\output_yolo_crop_test\\Dieu_0277_png.rf.e1eceac15c516d34668a829641b62911_plate_0.jpg\n",
      "Cropped plates for C:\\Users\\ADMIN\\Desktop\\test_real\\results\\heavy\\Dieu_0297_png.rf.2e02ec770094214aebe84fb37f4af7b8.jpg:\n",
      " - D:\\ViTraLP\\output_yolo_crop_test\\Dieu_0297_png.rf.2e02ec770094214aebe84fb37f4af7b8_plate_0.jpg\n",
      "Cropped plates for C:\\Users\\ADMIN\\Desktop\\test_real\\results\\heavy\\Dieu_0297_png.rf.cba8d93ea7a38d0fc0cbe3a5046dd4a4.jpg:\n",
      " - D:\\ViTraLP\\output_yolo_crop_test\\Dieu_0297_png.rf.cba8d93ea7a38d0fc0cbe3a5046dd4a4_plate_0.jpg\n",
      "Cropped plates for C:\\Users\\ADMIN\\Desktop\\test_real\\results\\heavy\\Dieu_0297_png.rf.d3702cc1d5eac01c05cb3e46b194cb47.jpg:\n",
      " - D:\\ViTraLP\\output_yolo_crop_test\\Dieu_0297_png.rf.d3702cc1d5eac01c05cb3e46b194cb47_plate_0.jpg\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import os\n",
    "from typing import Union, List\n",
    "\n",
    "def detect_license_plates(image_paths: Union[str, List[str]],\n",
    "                          model_path,\n",
    "                          save_dir=r\"D:\\ViTraLP\\output_yolo_crop_test\",\n",
    "                          conf_thresh=0.4):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    # Load YOLO model\n",
    "    model = YOLO(model_path)\n",
    "\n",
    "    # Nếu là 1 folder, lấy toàn bộ ảnh trong folder\n",
    "    if isinstance(image_paths, str) and os.path.isdir(image_paths):\n",
    "        supported_exts = ('.jpg', '.jpeg', '.png', '.bmp')\n",
    "        image_paths = [os.path.join(image_paths, f) for f in os.listdir(image_paths)\n",
    "                       if f.lower().endswith(supported_exts)]\n",
    "    elif isinstance(image_paths, str):  # Là 1 file ảnh\n",
    "        image_paths = [image_paths]\n",
    "\n",
    "    all_cropped_paths = []\n",
    "\n",
    "    for image_path in image_paths:\n",
    "        results = model(image_path, conf=conf_thresh)\n",
    "        result = results[0]\n",
    "        boxes = result.boxes.xyxy.cpu().numpy()\n",
    "\n",
    "        image = cv2.imread(image_path)\n",
    "        cropped_paths = []\n",
    "\n",
    "        for i, (x1, y1, x2, y2) in enumerate(boxes):\n",
    "            x1, y1, x2, y2 = map(int, [x1, y1, x2, y2])\n",
    "            crop = image[y1:y2, x1:x2]\n",
    "\n",
    "            basename = os.path.splitext(os.path.basename(image_path))[0]\n",
    "            crop_filename = f\"{basename}_plate_{i}.jpg\"\n",
    "            crop_path = os.path.join(save_dir, crop_filename)\n",
    "\n",
    "            cv2.imwrite(crop_path, crop)\n",
    "            cropped_paths.append(crop_path)\n",
    "\n",
    "        all_cropped_paths.append({\"image\": image_path, \"crops\": cropped_paths})\n",
    "\n",
    "    return all_cropped_paths\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Bạn có thể truyền vào 1 folder chứa ảnh\n",
    "    image_folder = r\"C:\\Users\\ADMIN\\Desktop\\test_real\\results\\heavy\"\n",
    "    model_path = r\"D:\\ViTraLP\\yolo_finetuned_weights\\yolo11_medium_rainy_200_best.pt\"\n",
    "    \n",
    "    results = detect_license_plates(image_folder, model_path)\n",
    "\n",
    "    for result in results:\n",
    "        print(f\"Cropped plates for {result['image']}:\")\n",
    "        for path in result['crops']:\n",
    "            print(\" -\", path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PReNet enhance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n",
      "\n",
      "PReNet(\n",
      "  (conv0): Sequential(\n",
      "    (0): Conv2d(6, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (res_conv1): Sequential(\n",
      "    (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU()\n",
      "  )\n",
      "  (res_conv2): Sequential(\n",
      "    (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU()\n",
      "  )\n",
      "  (res_conv3): Sequential(\n",
      "    (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU()\n",
      "  )\n",
      "  (res_conv4): Sequential(\n",
      "    (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU()\n",
      "  )\n",
      "  (res_conv5): Sequential(\n",
      "    (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU()\n",
      "  )\n",
      "  (conv_i): Sequential(\n",
      "    (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): Sigmoid()\n",
      "  )\n",
      "  (conv_f): Sequential(\n",
      "    (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): Sigmoid()\n",
      "  )\n",
      "  (conv_g): Sequential(\n",
      "    (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): Tanh()\n",
      "  )\n",
      "  (conv_o): Sequential(\n",
      "    (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): Sigmoid()\n",
      "  )\n",
      "  (conv): Sequential(\n",
      "    (0): Conv2d(32, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      ")\n",
      "Total number of parameters: 168963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_23348\\1937457616.py:34: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(logdir))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dieu_0269_png.rf.ae3a7d4751b1ab6bd2efded1dd2fcf32.jpg : 0.5168132781982422\n",
      "Dieu_0269_png.rf.bb70c387d8e9f8c951a2447f63c4c894.jpg : 0.31981897354125977\n",
      "Dieu_0269_png.rf.e9f24a1e2e608c2cb3471d5a47be62ab.jpg : 0.31943535804748535\n",
      "Dieu_0277_png.rf.1e63158cf701baedf83e2f4bda73318b.jpg : 0.32265424728393555\n",
      "Dieu_0277_png.rf.2d7438662ce4848d6f19bce0eb158043.jpg : 0.31897544860839844\n",
      "Dieu_0277_png.rf.e1eceac15c516d34668a829641b62911.jpg : 0.32131004333496094\n",
      "Dieu_0297_png.rf.2e02ec770094214aebe84fb37f4af7b8.jpg : 0.3188357353210449\n",
      "Dieu_0297_png.rf.cba8d93ea7a38d0fc0cbe3a5046dd4a4.jpg : 0.3201022148132324\n",
      "Dieu_0297_png.rf.d3702cc1d5eac01c05cb3e46b194cb47.jpg : 0.3212587833404541\n",
      "Avg. time: 0.3421337869432237\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from utils import *  # Đảm bảo file utils.py nằm cùng thư mục hoặc trong PYTHONPATH\n",
    "from networks import *  # Tương tự cho networks.py\n",
    "\n",
    "# Cấu hình đường dẫn và thông số\n",
    "logdir = r\"D:\\DSP_Project\\derain_PReNet\\PReNet\\logs\\finetuning\\heavy\\net_epoch50_heavy.pth\"\n",
    "data_path = r\"C:\\Users\\ADMIN\\Desktop\\test_real\\rainy\\heavy\"\n",
    "save_path = r\"C:\\Users\\ADMIN\\Desktop\\test_real\\results\\heavy\"\n",
    "use_GPU = True\n",
    "gpu_id = \"0\"\n",
    "recurrent_iter = 6\n",
    "\n",
    "# Thiết lập GPU\n",
    "if use_GPU:\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = gpu_id\n",
    "\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "# Khởi tạo mô hình\n",
    "print('Loading model...\\n')\n",
    "model = PReNet(recurrent_iter, use_GPU)\n",
    "print_network(model)\n",
    "\n",
    "if use_GPU:\n",
    "    model = model.cuda()\n",
    "\n",
    "# Load trọng số\n",
    "model.load_state_dict(torch.load(logdir))\n",
    "model.eval()\n",
    "\n",
    "time_test = 0\n",
    "count = 0\n",
    "\n",
    "for img_name in os.listdir(data_path):\n",
    "    if is_image(img_name):\n",
    "        img_path = os.path.join(data_path, img_name)\n",
    "\n",
    "        # Đọc và chuẩn hóa ảnh\n",
    "        y = cv2.imread(img_path)\n",
    "        b, g, r = cv2.split(y)\n",
    "        y = cv2.merge([r, g, b])  # Chuyển sang RGB\n",
    "\n",
    "        y = normalize(np.float32(y))\n",
    "        y = np.expand_dims(y.transpose(2, 0, 1), 0)\n",
    "        y = Variable(torch.Tensor(y))\n",
    "\n",
    "        if use_GPU:\n",
    "            y = y.cuda()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            if use_GPU:\n",
    "                torch.cuda.synchronize()\n",
    "            start_time = time.time()\n",
    "\n",
    "            out, _ = model(y)\n",
    "            out = torch.clamp(out, 0., 1.)\n",
    "\n",
    "            if use_GPU:\n",
    "                torch.cuda.synchronize()\n",
    "            end_time = time.time()\n",
    "\n",
    "            dur_time = end_time - start_time\n",
    "            time_test += dur_time\n",
    "            print(img_name, ':', dur_time)\n",
    "\n",
    "        # Chuyển tensor về ảnh\n",
    "        out_np = out.data.cpu().numpy().squeeze() if use_GPU else out.data.numpy().squeeze()\n",
    "        save_out = np.uint8(255 * out_np).transpose(1, 2, 0)\n",
    "        b, g, r = cv2.split(save_out)\n",
    "        save_out = cv2.merge([r, g, b])  # Trở lại BGR để lưu bằng OpenCV\n",
    "\n",
    "        cv2.imwrite(os.path.join(save_path, img_name), save_out)\n",
    "        count += 1\n",
    "\n",
    "print('Avg. time:', time_test / count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OCR recognizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== eh1_plate_0.jpg ===\n",
      "Text: 29A, Confidence: 0.89\n",
      "Text: 735.70, Confidence: 0.99\n",
      "\n",
      "=== Tgmt_0641_png.rf.a483413bd4b4a3e16a2e6a28ab88948f_plate_0.jpg ===\n",
      "Text: 29A, Confidence: 0.81\n",
      "Text: 735.70, Confidence: 0.99\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from paddleocr import PaddleOCR\n",
    "\n",
    "# Ép PaddleOCR chỉ dùng CPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "\n",
    "# Khởi tạo OCR với model nhận dạng tùy chỉnh\n",
    "ocr_model = PaddleOCR(                                      \n",
    "    use_angle_cls=False,\n",
    "    det=False,\n",
    "    rec=True,\n",
    "    text_recognition_model_dir=r\"D:/ViTraLP/original_weights_paddle\",\n",
    "    lang='en',\n",
    "    show_log=False\n",
    ")\n",
    "\n",
    "# Sửa 2 ký tự đầu tiên nếu nhận nhầm\n",
    "def correct_first_two_digits(text):\n",
    "    char_to_digit = {\n",
    "        'O': '0', 'o': '0', 'Q': '0',\n",
    "        'I': '1', 'l': '1', 'L': '1',\n",
    "        'Z': '2', 'S': '5', 'B': '8', 'G': '6'\n",
    "    }\n",
    "    text = text.strip()\n",
    "    if len(text) < 2:\n",
    "        return text\n",
    "    new_text = list(text)\n",
    "    for i in range(2):\n",
    "        if not new_text[i].isdigit():\n",
    "            new_text[i] = char_to_digit.get(new_text[i], '0')\n",
    "    return ''.join(new_text)\n",
    "\n",
    "# Hàm OCR một ảnh và in ra từng kết quả\n",
    "def recognize_and_print(img_path):\n",
    "    result = ocr_model.ocr(img_path, cls=False)\n",
    "    print(f\"\\n=== {os.path.basename(img_path)} ===\")\n",
    "    if result and result[0]:\n",
    "        for line in result[0]:\n",
    "            (box, (text, confidence)) = line\n",
    "            corrected_text = correct_first_two_digits(text)\n",
    "            print(f\"Text: {corrected_text}, Confidence: {confidence:.2f}\")\n",
    "    else:\n",
    "        print(\"No text detected\")\n",
    "\n",
    "# OCR toàn bộ ảnh trong thư mục\n",
    "image_folder = r\"D:\\ViTraLP\\output_yolo_crop_test\"\n",
    "valid_exts = ['.jpg', '.jpeg', '.png', '.bmp']\n",
    "\n",
    "for filename in os.listdir(image_folder):\n",
    "    ext = os.path.splitext(filename)[-1].lower()\n",
    "    if ext in valid_exts:\n",
    "        img_path = os.path.join(image_folder, filename)\n",
    "        try:\n",
    "            recognize_and_print(img_path)\n",
    "        except Exception as e:\n",
    "            print(f\"{filename}: Error - {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025/07/21 10:23:50] ppocr DEBUG: Namespace(help='==SUPPRESS==', use_gpu=True, use_xpu=False, use_npu=False, ir_optim=True, use_tensorrt=False, min_subgraph_size=15, precision='fp32', gpu_mem=500, gpu_id=0, image_dir=None, page_num=0, det_algorithm='DB', det_model_dir='C:\\\\Users\\\\ADMIN/.paddleocr/whl\\\\det\\\\ch\\\\ch_PP-OCRv4_det_infer', det_limit_side_len=960, det_limit_type='max', det_box_type='quad', det_db_thresh=0.3, det_db_box_thresh=0.6, det_db_unclip_ratio=1.5, max_batch_size=10, use_dilation=False, det_db_score_mode='fast', det_east_score_thresh=0.8, det_east_cover_thresh=0.1, det_east_nms_thresh=0.2, det_sast_score_thresh=0.5, det_sast_nms_thresh=0.2, det_pse_thresh=0, det_pse_box_thresh=0.85, det_pse_min_area=16, det_pse_scale=1, scales=[8, 16, 32], alpha=1.0, beta=1.0, fourier_degree=5, rec_algorithm='SVTR_LCNet', rec_model_dir='C:\\\\Users\\\\ADMIN/.paddleocr/whl\\\\rec\\\\ch\\\\ch_PP-OCRv4_rec_infer', rec_image_inverse=True, rec_image_shape='3, 48, 320', rec_batch_num=6, max_text_length=25, rec_char_dict_path='C:\\\\Users\\\\ADMIN\\\\AppData\\\\Roaming\\\\Python\\\\Python310\\\\site-packages\\\\paddleocr\\\\ppocr\\\\utils\\\\ppocr_keys_v1.txt', use_space_char=True, vis_font_path='./doc/fonts/simfang.ttf', drop_score=0.5, e2e_algorithm='PGNet', e2e_model_dir=None, e2e_limit_side_len=768, e2e_limit_type='max', e2e_pgnet_score_thresh=0.5, e2e_char_dict_path='./ppocr/utils/ic15_dict.txt', e2e_pgnet_valid_set='totaltext', e2e_pgnet_mode='fast', use_angle_cls=False, cls_model_dir='C:\\\\Users\\\\ADMIN/.paddleocr/whl\\\\cls\\\\ch_ppocr_mobile_v2.0_cls_infer', cls_image_shape='3, 48, 192', label_list=['0', '180'], cls_batch_num=6, cls_thresh=0.9, enable_mkldnn=False, cpu_threads=10, use_pdserving=False, warmup=False, sr_model_dir=None, sr_image_shape='3, 32, 128', sr_batch_num=1, draw_img_save_dir='./inference_results', save_crop_res=False, crop_res_save_dir='./output', use_mp=False, total_process_num=1, process_id=0, benchmark=False, save_log_path='./log_output/', show_log=True, use_onnx=False, output='./output', table_max_len=488, table_algorithm='TableAttn', table_model_dir=None, merge_no_span_structure=True, table_char_dict_path=None, layout_model_dir=None, layout_dict_path=None, layout_score_threshold=0.5, layout_nms_threshold=0.5, kie_algorithm='LayoutXLM', ser_model_dir=None, re_model_dir=None, use_visual_backbone=True, ser_dict_path='../train_data/XFUND/class_list_xfun.txt', ocr_order_method=None, mode='structure', image_orientation=False, layout=True, table=True, ocr=True, recovery=False, use_pdf2docx_api=False, invert=False, binarize=False, alphacolor=(255, 255, 255), lang='ch', det=True, rec=True, type='ocr', ocr_version='PP-OCRv4', structure_version='PP-StructureV2')\n",
      "['__call__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'args', 'crop_image_res_index', 'draw_crop_rec_res', 'drop_score', 'ocr', 'page_num', 'text_detector', 'text_recognizer', 'use_angle_cls']\n"
     ]
    }
   ],
   "source": [
    "from paddleocr import PaddleOCR\n",
    "ocr = PaddleOCR(use_angle_cls=False)\n",
    "\n",
    "# In toàn bộ thuộc tính để tìm path chứa model\n",
    "print(dir(ocr))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kurama",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
